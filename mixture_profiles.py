# Copyright 2011 David W. Hogg and Dustin Lang.  All rights reserved.

if __name__ == '__main__':
	import matplotlib
	matplotlib.use('Agg')
	import pylab as plt
	import matplotlib.cm as cm
import numpy as np
import scipy.spatial.distance as scp

# magic arrays, generated by running optimize_mixture_profiles.py:
exp_amp = np.array([3.31636565e-05, 1.06478564e-03, 1.33260624e-02, 1.06217866e-01,
		    6.09924868e-01, 2.43600369e+00, 5.34553250e+00, 3.41379672e+00])
exp_var = np.array([4.91509189e-05, 7.91283025e-04, 5.06909854e-03, 2.30018199e-02,
		    8.50523831e-02, 2.73398885e-01, 7.93675135e-01, 2.17065603e+00])
dev_amp = np.array([1.36305372e-02, 1.08889599e-01, 3.68235229e-01, 9.26647361e-01,
		    2.00002437e+00, 3.77384257e+00, 6.01053703e+00, 7.22968202e+00])
dev_var = np.array([1.34654444e-04, 5.04128747e-04, 1.88518562e-03, 7.20439754e-03,
		    2.87959626e-02, 1.25118904e-01, 6.38235086e-01, 4.76437813e+00])

def get_exp_mixture():
	return MixtureOfGaussians(exp_amp, np.zeros((exp_amp.size, 2)), exp_var)

def get_dev_mixture():
	return MixtureOfGaussians(dev_amp, np.zeros((dev_amp.size, 2)), dev_var)

class MixtureOfGaussians():

	# symmetrize is an unnecessary step in principle, but in practice?
	def __init__(self, amp, mean, var):
		self.amp = np.array(amp).astype(float)
		self.mean = np.atleast_2d(np.array(mean)).astype(float)
		(self.K, self.D) = self.mean.shape
		self.set_var(var)
		self.symmetrize()
		self.test()

	def __str__(self):
		result = "MixtureOfGaussians instance"
		result += " with %d components in %d dimensions:\n" % (self.K, self.D)
		result += " amp	 = %s\n" % self.amp.__str__()
		result += " mean = %s\n" % self.mean.__str__()
		result += " var	 = %s\n" % self.var.__str__()
		return result

	def set_var(self, var):
		if var.size == self.K:
			self.var = np.zeros((self.K, self.D, self.D))
			for d in range(self.D):
				self.var[:,d,d] = var
		else:
			# atleast_3d makes bizarre choices about which axes to expand...
			#self.var = np.atleast_3d(np.array(var))
			#print 'var', self.var.shape
			self.var = np.array(var).astype(float)
	def symmetrize(self):
		for i in range(self.D):
			for j in range(i):
				tmpij = 0.5 * (self.var[:,i,j] + self.var[:,j,i])
				self.var[:,i,j] = tmpij
				self.var[:,j,i] = tmpij

	# very harsh testing, and expensive
	def test(self):
		assert(self.amp.shape == (self.K, ))
		assert(self.mean.shape == (self.K, self.D))
		assert(self.var.shape == (self.K, self.D, self.D))
		for k in range(self.K):
			thisvar = self.var[k]
			assert(np.sum(thisvar.T - thisvar) == 0.)
			assert(np.linalg.det(thisvar) >= 0.)

	def copy(self):
		return MixtureOfGaussians(self.amp, self.mean, self.var)

	def normalize(self):
		self.amp /= np.sum(self.amp)

	def extend(self, other):
		assert(self.D == other.D)
		self.K = self.K + other.K
		self.amp = np.append(self.amp, other.amp)
		self.mean = np.reshape(np.append(self.mean, other.mean), (self.K, self.D))
		self.var = np.reshape(np.append(self.var, other.var), (self.K, self.D, self.D))
		self.test

	def apply_affine(self, shift, scale):
		'''
		shift: D-vector offset
		scale: DxD-matrix transformation
		'''
		assert(shift.shape == (self.D,))
		assert(scale.shape == (self.D, self.D))
		newmean = self.mean + shift
		newvar = self.var.copy()
		for k in range(self.K):
			newvar[k,:,:] = np.dot(scale.T, np.dot(self.var[k,:,:], scale))
		return MixtureOfGaussians(self.amp, newmean, newvar)

	# dstn: should this be called "correlate"?
	def convolve(self, other):
		assert(self.D == other.D)
		newK = self.K * other.K
		D = self.D
		newamp = np.zeros((newK))
		newmean = np.zeros((newK, D))
		newvar = np.zeros((newK, D, D))
		newk = 0
		for k in range(other.K):
			nextnewk = newk + self.K
			newamp[newk:nextnewk] = self.amp * other.amp[k]
			newmean[newk:nextnewk,:] = self.mean + other.mean[k]
			newvar[newk:nextnewk,:,:] = self.var + other.var[k]
			newk = nextnewk
		return MixtureOfGaussians(newamp, newmean, newvar)

	# ideally pos is a numpy array shape (N, self.D)
	# returns a numpy array shape (N)
	# may fail for self.D == 1
	# loopy
	def evaluate_3(self, pos):
		if pos.size == self.D:
			pos = np.reshape(pos, (1, self.D))
		(N, D) = pos.shape
		assert(self.D == D)
		twopitotheD = (2.*np.pi)**self.D
		result = np.zeros(N)
		for k in range(self.K):
			# pos is (N, D)
			# mean[k] is (D,)
			dpos = pos - self.mean[k]
			dsq = np.sum(dpos * np.dot(dpos, np.linalg.inv(self.var[k])), axis=1)
			I = (dsq < 700)
			result[I] += (self.amp[k] / np.sqrt(twopitotheD * np.linalg.det(self.var[k]))) * np.exp(-0.5 * dsq[I])
		return result

	def evaluate_1(self, pos):
		if pos.size == self.D:
			pos = np.reshape(pos, (1, self.D))
		(N, D) = pos.shape
		assert(self.D == D)
		twopitotheD = (2.*np.pi)**self.D
		result = np.zeros(N)
		for k in range(self.K):
			dsq = scp.cdist(pos, self.mean[np.newaxis, k], 'mahalanobis', VI=np.linalg.inv(self.var[k]))[:,0]**2
			I = (dsq < 700)
			result[I] += (self.amp[k] / np.sqrt(twopitotheD * np.linalg.det(self.var[k]))) * np.exp(-0.5 * dsq[I])
		return result

	def evaluate_2(self, pos):
		from mix import c_gauss_2d
		if pos.size == self.D:
			pos = np.reshape(pos, (1, self.D))
		(N, D) = pos.shape
		assert(self.D == D)
		result = np.zeros(N)
		rtn = c_gauss_2d(pos, self.amp, self.mean, self.var, result)
		if rtn == -1:
			raise RuntimeError('c_gauss_2d failed')
		x, y = meshgrid()
		return result

	def evaluate_grid_dstn(self, xlo, xhi, ylo, yhi):
		from mix import c_gauss_2d_grid
		assert(self.D == 2)
		NX = xhi - xlo - 1
		NY = yhi - ylo - 1
		result = np.zeros((NY, NX))
		rtn = c_gauss_2d_grid(xlo, xhi, ylo, yhi, self.amp, self.mean,
							  self.var, result)
		if rtn == -1:
			raise RuntimeError('c_gauss_2d_grid failed')
		return result

	def evaluate_grid_hogg(self, xlo, xhi, ylo, yhi):
		assert(self.D == 2)
		xy = np.array(np.meshgrid(range(xlo, xhi), range(ylo, yhi)))
		D, nx, ny = xy.shape
		xy = xy.reshape((D, nx * ny)).T
		result = self.evaluate_1(xy)
		return result.reshape((nx, ny))

	evaluate = evaluate_2
	evaluate_grid = evaluate_grid_hogg

# input: a mixture, a 2d array of x,y minimum values, and a 2d array of x,y maximum values
# output: a patch
def mixture_to_patch(mixture, posmin, posmax):
	return mixture.evaluate_grid(int(posmin[0]), int(posmax[0]),
								 int(posmin[1]), int(posmax[1]))
'''
	xl = np.arange(posmin[0], posmax[0], 1.)
	nx = xl.size
	yl = np.arange(posmin[1], posmax[1], 1.)
	ny = yl.size
	x, y = np.meshgrid(xl, yl)
	pos = np.transpose(np.array([np.ravel(x), np.ravel(y)]))
	return np.reshape(mixture.evaluate(pos), (ny, nx))
'''

def model_to_patch(model, scale, posmin, posmax):
	xl = np.arange(posmin[0], posmax[0]+1., 1.)
	nx = xl.size
	yl = np.arange(posmin[1], posmax[1]+1., 1.)
	ny = yl.size
	x, y = np.meshgrid(xl, yl)
	dist = np.sqrt(np.ravel(x)**2 + np.ravel(y)**2)
	if model == 'exp':
		return np.reshape(np.exp(-1. * (dist / scale)), (ny, nx))
	if model == 'dev':
		return np.reshape(np.exp(-1. * (dist / scale)**0.25), (ny, nx))
	else:
		return 0.

def functional_test_circular_mixtures():
	exp_mixture = MixtureOfGaussians(exp_amp, np.zeros((exp_amp.size, 2)), exp_var)
	dev_mixture = MixtureOfGaussians(dev_amp, np.zeros((dev_amp.size, 2)), dev_var)
	pos = np.random.uniform(-5.,5.,size=(24,2))
	exp_eva = exp_mixture.evaluate(pos)
	dev_eva = dev_mixture.evaluate(pos)
	(N, D) = pos.shape
	for n in range(N):
		print '(%+6.3f %+6.3f) exp: %+8.5f' % (pos[n,0], pos[n,1], exp_eva[n] - np.exp(-1. * np.sqrt(np.sum(pos[n] * pos[n]))))
		print '(%+6.3f %+6.3f) dev: %+8.5f' % (pos[n,0], pos[n,1], dev_eva[n] - np.exp(-1. * np.sqrt(np.sum(pos[n] * pos[n]))**0.25))

def functional_test_patch_maker(fn, psf=None):
	scale = 30.
	posmin = np.array([-3, -5]) * scale
	posmax = np.array([1, 1]) * scale
	exp_mixture = MixtureOfGaussians(exp_amp*scale*scale, np.zeros((exp_amp.size, 2)), exp_var*scale*scale)

	# Works! exp_mixture.apply_affine(np.array([10,-30]), np.eye(2))
	S = np.array([[1,0],[0,0.5]])
	print 'Det', np.linalg.det(S)
	S /= np.sqrt(np.linalg.det(S))
	print 'Det', np.linalg.det(S)
	r = np.deg2rad(30.)
	cr = np.cos(r)
	sr = np.sin(r)
	S = np.dot(S, np.array([[cr, sr],[-sr, cr]]))
	print 'Det', np.linalg.det(S)
	exp_mixture = exp_mixture.apply_affine(np.array([10,-30]), S)

	if psf is not None:
		exp_mixture = exp_mixture.convolve(psf)
	exp_mix_patch = mixture_to_patch(exp_mixture, posmin, posmax)
	exp_patch = model_to_patch('exp', scale, posmin, posmax)
	dev_mixture = MixtureOfGaussians(dev_amp*scale*scale, np.zeros((dev_amp.size, 2)), dev_var*scale*scale)
	if psf is not None:
		dev_mixture = dev_mixture.convolve(psf)
	dev_mix_patch = mixture_to_patch(dev_mixture, posmin, posmax)
	dev_patch = model_to_patch('dev', scale, posmin, posmax)
	cmap = cm.gray
	vmin = -0.5
	vmax = 1.0
	factor = 100.
	plt.clf()
	plt.subplot(231)
	plt.imshow(exp_mix_patch, interpolation='nearest', origin='lower', cmap=cmap, vmin=vmin, vmax=vmax)
	plt.colorbar()
	plt.subplot(232)
	plt.imshow(exp_patch, interpolation='nearest', origin='lower', cmap=cmap, vmin=vmin, vmax=vmax)
	plt.colorbar()
	plt.subplot(233)
	plt.imshow(exp_mix_patch - exp_patch, interpolation='nearest', origin='lower', cmap=cmap, vmin=-1./factor, vmax=1./factor)
	plt.colorbar()
	plt.subplot(234)
	plt.imshow(dev_mix_patch, interpolation='nearest', origin='lower', cmap=cmap, vmin=vmin, vmax=vmax)
	plt.colorbar()
	plt.subplot(235)
	plt.imshow(dev_patch, interpolation='nearest', origin='lower', cmap=cmap, vmin=vmin, vmax=vmax)
	plt.colorbar()
	plt.subplot(236)
	plt.imshow(dev_mix_patch - dev_patch, interpolation='nearest', origin='lower', cmap=cmap, vmin=-1./factor, vmax=1./factor)
	plt.colorbar()
	plt.savefig(fn)

if __name__ == '__main__':
	# functional_test_circular_mixtures()
	psfamp = np.array([0.7,0.2,0.1])
	psfmean = np.zeros((3,2))
	psfvar = np.zeros((3,2,2))
	psfvar[0,0,0] = 1.2**2
	psfvar[0,1,1] = psfvar[0,0,0]
	psfvar[1,0,0] = 2.4**2
	psfvar[1,1,1] = psfvar[1,0,0]
	psfvar[2,0,0] = 3.6**2
	psfvar[2,1,1] = psfvar[2,0,0]
	psf = MixtureOfGaussians(psfamp, psfmean, psfvar)
	functional_test_patch_maker('test_patch.png')
	functional_test_patch_maker('test_psf_patch.png', psf=psf)
